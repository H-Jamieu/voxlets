{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt \n",
      "import cPickle as pickle\n",
      "import sys\n",
      "sys.path.append('/Users/Michael/projects/shape_sharing/src/common/')\n",
      "sys.path.append('/Users/Michael/projects/shape_sharing/src/')\n",
      "sys.path.append('../bigbird_images3/')\n",
      "\n",
      "import paths\n",
      "import voxel_data\n",
      "import mesh\n",
      "import images\n",
      "import features\n",
      "from thickness_regress import combine_data\n",
      "import scipy.io\n",
      "\n",
      "# loading OSD names:\n",
      "with open('../voxlets/real_world_prediction/names.txt', 'r') as f:\n",
      "    names = [fline.strip() for fline in f]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "voxel_size = (0.1/15)/2\n",
      "\n",
      "def convert_bb_transform_to_prediction_transform(inv_H_trans_in, gt_mesh_origin):\n",
      "    transform_for_mesh = np.linalg.inv(inv_H_trans_in)\n",
      "    extra = np.dot(transform_for_mesh[:3, :3], (gt_mesh_origin).T)\n",
      "    transform_for_mesh[:3, 3] += extra\n",
      "    transform_for_mesh[:3, 3] /= voxel_size\n",
      "    transform_for_mesh[:3, 3] *= 0.1 # scaling for blender\n",
      "    return transform_for_mesh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_pose(cam_inv_H, gt_grid_origin):\n",
      "\n",
      "    return convert_bb_transform_to_prediction_transform(cam_inv_H, gt_grid_origin).T\n",
      "\n",
      "# loop over all models and view\n",
      "f = open('../voxlets/real_world_prediction/names.txt', 'r')\n",
      "for fline in f:\n",
      "    name = fline.strip()\n",
      "    \n",
      "    osdsavefolder = paths.base_path + \"other_3D/osd/OSD-0.2-depth/troll_predictions/\"\n",
      "    loadpath = osdsavefolder + name + \".pkl\"\n",
      "    accum = pickle.load(open(loadpath, 'rb'))\n",
      "    \n",
      "    im = images.RealRGBD()\n",
      "    im.load_from_mat(name)\n",
      "    \n",
      "    # get the poses for this view\n",
      "    this_pose = get_pose(im.cam.inv_H, accum.origin)\n",
      "    print this_pose\n",
      "    \n",
      "    # save this pose to file\n",
      "    savename = paths.base_path + \"other_3D/osd/OSD-0.2-depth/camera_poses/\" + name + \".mat\"\n",
      "    D = dict(camera_poses=this_pose)\n",
      "    scipy.io.savemat(savename, D, do_compression=True)\n",
      "\n",
      "    \n",
      "    print \"Done \" + name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now will try it with the saved sequences\n",
      "\n",
      "def load_prediction(accum):\n",
      "    '''\n",
      "    loads a prediction of filled voxels and converts to the [ijk] locations \n",
      "    of the filled voxels\n",
      "    '''\n",
      "#     loadpath = paths.voxlet_prediction_path % ('oma', modelname, view)\n",
      "#     loadpath = loadpath.replace('predictions', 'troll_predictions')\n",
      "#     D = scipy.io.loadmat(loadpath )\n",
      "#     predicted_grid = D['prediction']\n",
      "    return np.array(np.nonzero(accum.V < 0)).T.astype(float) * 0.1 #voxel_size\n",
      "\n",
      "\n",
      "import Image\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def apply_homo_transformation(xyz, trans):\n",
      "    '''\n",
      "    apply a 4x4 transformation matrix to the vertices\n",
      "    '''\n",
      "    n = xyz.shape[0]\n",
      "    temp = np.concatenate((xyz, np.ones((n, 1))), axis=1).T\n",
      "    temp_transformed = trans.dot(temp).T\n",
      "    return temp_transformed\n",
      "\n",
      "\n",
      "def project_into_camera(xyz, trans):\n",
      "    '''\n",
      "    apply a 3x3 transformation matrix to the vertices\n",
      "    vertices assumed to already be in coordinates of the camera\n",
      "    '''\n",
      "    to_add = np.zeros((3, 1))\n",
      "    temp_trans = np.concatenate((trans, to_add), axis=1)\n",
      "    projected_points = np.dot(temp_trans, xyz.T).T\n",
      "    \n",
      "    # normalise by the depth component\n",
      "    projected_points[:, 0] /= projected_points[:, 2]\n",
      "    projected_points[:, 1] /= projected_points[:, 2]\n",
      "    return projected_points\n",
      "\n",
      "\n",
      "pred = load_prediction(accum)\n",
      "\n",
      "transformed = apply_homo_transformation(pred, this_pose.T)\n",
      "camera_projection = project_into_camera(transformed, im.cam.K)\n",
      "\n",
      "plt.imshow(im.rgb)\n",
      "plt.hold(True)\n",
      "plt.plot(camera_projection[:, 0], camera_projection[:, 1], '.')\n",
      "plt.axis('equal')\n",
      "plt.hold(False)\n",
      "print im.cam.K"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}