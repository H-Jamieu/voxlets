{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "the aim is to do shoebox extraction, clustering, assignment and feature extracted and forest training\n",
      "All in one notebook file\n",
      "for one object\n",
      "'''\n",
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt \n",
      "import cPickle as pickle\n",
      "import sys\n",
      "sys.path.append('/Users/Michael/projects/shape_sharing/src/')\n",
      "sys.path.append('../bigbird_images3/')\n",
      "\n",
      "from common import paths\n",
      "from common import voxel_data\n",
      "from common import mesh\n",
      "from common import images\n",
      "from common import features\n",
      "from thickness_regress import combine_data\n",
      "import reconstructer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loading clusters and forest\n",
      "forest = pickle.load(open(paths.voxlet_model_path, 'rb'))\n",
      "forest_pca = pickle.load(open(paths.voxlet_model_pca_path, 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "km = pickle.load(open(paths.voxlet_dict_path, 'rb'))\n",
      "km_pca = pickle.load(open(paths.voxlet_pca_dict_path, 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now will use this prediction to reconstruct one of the original objects from an image\n",
      "test_view = paths.views[10]\n",
      "modelname = paths.test_names[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def random_sample_from_mask(mask, num_samples):\n",
      "    '''sample random points from a mask'''\n",
      "    \n",
      "    indices = np.array(np.nonzero(mask)).T\n",
      "    samples = np.random.randint(0, indices.shape[0], num_samples)\n",
      "    return indices[samples, :]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (12.0, 4.0)\n",
      "\n",
      "test_im = images.CroppedRGBD()\n",
      "test_im.load_bigbird_from_mat(modelname, test_view)\n",
      "\n",
      "\"Sampling from image\"\n",
      "test_mask = ~np.isnan(test_im.frontrender)\n",
      "idxs = random_sample_from_mask(test_mask, 2000)\n",
      "\n",
      "\"Extracting features\"\n",
      "combined_features = test_im.get_features(idxs)\n",
      "\n",
      "\"Classifying the features\"\n",
      "pred_classes = forest.predict(combined_features)\n",
      "hist_classes = np.bincount(pred_classes)\n",
      "print pred_classes.shape\n",
      "print hist_classes.shape\n",
      "\n",
      "plt.subplot(141)\n",
      "plt.imshow(test_im.rgb)\n",
      "plt.subplot(142)\n",
      "plt.hist(pred_classes, 50)\n",
      "max_class = np.argmax(hist_classes)\n",
      "plt.subplot(143)\n",
      "plt.imshow(np.mean(km.cluster_centers_[max_class].reshape(paths.voxlet_shape), axis=2))\n",
      "plt.subplot(144)\n",
      "plt.imshow(np.mean(km.cluster_centers_[max_class].reshape(paths.voxlet_shape), axis=1))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"Classifying with confidence\"\n",
      "plt.rcParams['figure.figsize'] = (18.0, 8.0)\n",
      "\n",
      "from scipy.stats import mode\n",
      "\n",
      "# my predictions from each tree\n",
      "tree_predictions = np.array([tree.predict(combined_features) for tree in forest.estimators_]).T\n",
      "print tree_predictions.shape\n",
      "print np.max(tree_predictions)\n",
      "# The tree is only predicting up to 76 classes\n",
      "print forest.classes_\n",
      "pred_classes = forest.predict(combined_features)\n",
      "print np.max(pred_classes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklean_probs = forest.predict_proba(combined_features)\n",
      "print sklean_probs.shape\n",
      "small_number = 0.0001\n",
      "entropy = -np.sum(sklean_probs+small_number * np.log(sklean_probs+small_number), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loading ground truth voxel grid\n",
      "vgrid = voxel_data.BigBirdVoxels()\n",
      "vgrid.load_bigbird(modelname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import pdist, squareform\n",
      "D = squareform(pdist(km.cluster_centers_))\n",
      "\n",
      "def voxlet_medioid(indices):\n",
      "    '''\n",
      "    D is a NxN distance matrix between all pairs of voxlets\n",
      "    indices is a 1 x K vector of voxlet indices\n",
      "    returns the voxlet idx which is the medioid of everythin in indices\n",
      "    '''\n",
      "    sums = [D[:, int(ind)] for ind in indices]\n",
      "    sums = np.sum(np.array(sums), axis=0)\n",
      "    return np.argmin(sums)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now will use this prediction to reconstruct one of the original objects from an image\n",
      "\n",
      "\"Sampling from image\"\n",
      "test_mask = ~np.isnan(test_im.frontrender)\n",
      "idxs = random_sample_from_mask(test_mask, 2000)\n",
      "\n",
      "\"Extracting features\"\n",
      "combined_features = test_im.get_features(idxs)\n",
      "\n",
      "\"Classifying the features\"\n",
      "pred_classes = forest.predict(combined_features)\n",
      "#plt.hist(pred_classes, 50)\n",
      "\n",
      "# now want to reconstruct the image\n",
      "world_xyz = test_im.get_world_xyz()\n",
      "world_norms = test_im.get_world_normals()\n",
      "\n",
      "# here set up the grid to fill\n",
      "accum = voxel_data.UprightAccumulator(vgrid.V.shape)\n",
      "accum.set_voxel_size(vgrid.vox_size)\n",
      "accum.set_origin(vgrid.origin, vgrid.R)\n",
      "\n",
      "# set up order to approach the problem in \n",
      "order_to_fill = entropy.argsort()[::-1]\n",
      "\n",
      "# loop over all the predictions\n",
      "count = 0\n",
      "for idx_idx in order_to_fill:\n",
      "\n",
      "    # forming a medioid of all the voxlets in this cluster...    \n",
      "    #all_indices = tree_predictions[idx_idx]\n",
      "    #cluster_center = km.cluster_centers_[int(voxlet_medioid(all_indices))]\n",
      "    #cluster_center = km.cluster_centers_[int(all_indices[0])]\n",
      "    #print all_indices\n",
      "    \n",
      "\n",
      "    index = idxs[idx_idx]\n",
      "    \n",
      "    # convert to linear idx\n",
      "    point_idx = index[0] * test_im.mask.shape[1] + index[1]\n",
      "    \n",
      "    # look up the cluster center\n",
      "    cluster_center = km.cluster_centers_[int(pred_classes[idx_idx])]\n",
      "        \n",
      "    shoebox = voxel_data.ShoeBox(paths.voxlet_shape) # grid size\n",
      "    shoebox.set_p_from_grid_origin(paths.voxlet_centre) #m\n",
      "    shoebox.set_voxel_size(paths.voxlet_size) #m\n",
      "    shoebox.initialise_from_point_and_normal(world_xyz[point_idx], \n",
      "                                             world_norms[point_idx], \n",
      "                                             np.array([0, 0, 1]))\n",
      "    \n",
      "    # filling in the shoebox from the cluster center\n",
      "    shoebox.V = cluster_center.reshape(paths.voxlet_shape)\n",
      "\n",
      "    accum.add_voxlet(shoebox)\n",
      "    \n",
      "    print \"Done \" + str(count) + \" of \" + str(idxs.shape[0])\n",
      "    count += 1\n",
      "    if count > 20: break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "axis_to_use = 0\n",
      "slice_idx = 50\n",
      "plt.subplot(121)\n",
      "plt.imshow(np.flipud(np.mean(accum.compute_average(), axis=axis_to_use).T))\n",
      "#plt.imshow(accum.compute_average()[:, :, slice_idx])\n",
      "plt.colorbar()\n",
      "plt.subplot(122)\n",
      "plt.imshow(np.flipud(np.mean(vgrid.V, axis=axis_to_use).T))\n",
      "#plt.imshow(vgrid.V[:, :, slice_idx])\n",
      "plt.colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    }
   ],
   "metadata": {}
  }
 ]
}