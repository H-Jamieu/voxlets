{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt \n",
      "\n",
      "import numpy as np\n",
      "import cPickle as pickle\n",
      "import scipy.io\n",
      "import sys, os\n",
      "sys.path.append(os.path.expanduser('~/projects/shape_sharing/src/'))\n",
      "from sklearn.cluster import MiniBatchKMeans\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "from common import paths\n",
      "from common import voxel_data\n",
      "from common import images\n",
      "\n",
      "# parameters\n",
      "subsample_length = 2000 # how many points to cluster with\n",
      "#number_clusters = 200\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cluster_data(X, local_subsample_length, num_clusters):\n",
      "\n",
      "    # take subsample\n",
      "    if local_subsample_length > X.shape[0]:\n",
      "        print \"Too long! Making smaller\"\n",
      "        X_subset = X\n",
      "    else:\n",
      "        to_use_for_clustering = np.random.randint(0, X.shape[0], size=(local_subsample_length))\n",
      "        X_subset = X[to_use_for_clustering, :]\n",
      "\n",
      "    print X.shape\n",
      "    print X_subset.shape\n",
      "\n",
      "    # doing pca projection\n",
      "    pca = PCA(n_components=10)\n",
      "    pca.fit(X_subset)\n",
      "    \n",
      "    # doing clustering\n",
      "#    km = MiniBatchKMeans(n_clusters=num_clusters)\n",
      " #   km.fit(X_proj)\n",
      "    return pca\n",
      "\n",
      "\n",
      "def oma_pca(X, local_subsample_length, num_pca_dims):\n",
      "    \n",
      "    \n",
      "    \n",
      "    if local_subsample_length < X.shape[0]:\n",
      "        to_use_for_clustering = np.random.randint(0, X.shape[0], size=(local_subsample_length))\n",
      "        X = X[to_use_for_clustering, :]\n",
      "        \n",
      "    X = X - np.tile(np.mean(X, 0), (X.shape[0], 1))\n",
      "    (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
      "    X_ds = np.dot(X, M[:, 0:num_pca_dims])\n",
      "    return X_ds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initialise lists\n",
      "shoeboxes = []\n",
      "num_to_sample_per_model = 100\n",
      "\n",
      "for count, modelname in enumerate(paths.train_names):\n",
      "\n",
      "    print \"Processing \" + modelname\n",
      "\n",
      "    # loading the data\n",
      "    loadpath = paths.bigbird_training_data_mat_tsdf % modelname\n",
      "    \n",
      "    print \"Loading from \" + loadpath\n",
      "    D = scipy.io.loadmat(loadpath)\n",
      "    num_vox = D['shoeboxes'].shape[2]\n",
      "    temp_sbox = D['shoeboxes'].astype(np.float16).reshape((-1, num_vox))\n",
      "    print \"temp_sbox: \" + str(temp_sbox.shape)\n",
      "    \n",
      "    # subsampling\n",
      "    to_use = np.random.randint(0, temp_sbox.shape[0], size=(num_to_sample_per_model))\n",
      "    temp_sbox = temp_sbox[to_use, :]\n",
      "    print \"temp_sbox: \" + str(temp_sbox.shape)\n",
      "\n",
      "    # converting the subsampled array to tsdf\n",
      "    all_tsdf = []\n",
      "    for row in temp_sbox:\n",
      "        temp_vox = voxel_data.ShoeBox(paths.voxlet_shape)\n",
      "        temp_vox.set_voxel_size(paths.voxlet_size)\n",
      "        temp_vox.V = temp_sbox\n",
      "        to_add = temp_vox.compute_tsdf(0.03).astype(np.float16)\n",
      "        all_tsdf.append(to_add)\n",
      "\n",
      "    print \"length is \" + str(len(all_tsdf))\n",
      "    np_all_tsdf = np.array(all_tsdf)\n",
      "    print np_all_tsdf.shape\n",
      "\n",
      "    # adding to array\n",
      "    shoeboxes.append(np_all_tsdf)\n",
      "\n",
      "np_all_sboxes = np.concatenate(shoeboxes, axis=0)\n",
      "print \"All sboxes shape is \" + str(np_all_sboxes.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# clustering the sboxes - but only a subsample of them for speed!\n",
      "print \"Doing clustering or PCA or something\"\n",
      "#pca = cluster_data(np_all_sboxes, subsample_length, number_clusters)\n",
      "print np_all_sboxes.dtype\n",
      "#pca = oma_pca(np_all_sboxes, subsample_length, 10)\n",
      "print pca"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (12.0, 12.0)\n",
      "for count, comp in enumerate(pca.components_):\n",
      "    plt.subplot(4, 4, count+1)\n",
      "    temp= comp.reshape(paths.voxlet_shape)[:, :, 10]\n",
      "    plt.imshow(temp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now classify all features against this\n",
      "fitted = pca.transform(np_all_sboxes)\n",
      "print fitted.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx in range(50):\n",
      "    plt.subplot(10, 5, idx)\n",
      "    plt.imshow(np_all_sboxes[idx*200].reshape(paths.voxlet_shape)[:, :, 10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}