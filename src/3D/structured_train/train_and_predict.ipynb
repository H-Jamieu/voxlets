{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn import neighbors\n",
      "import cPickle as pickle\n",
      "import compute_data\n",
      "import displaying as disp\n",
      "import voxel_data\n",
      "import paths\n",
      "\n",
      "def nan_to_value(X, newval):\n",
      "\tX[np.isnan(X)] = newval\n",
      "\treturn X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelname = '109d55a137c042f5760315ac3bf2c13e'\n",
      "view_idx = 12\n",
      "\n",
      "# loading the features to test on and the ground truth data\n",
      "engine = compute_data.DepthFeatureEngine(modelname, view_idx+1)\n",
      "engine.sample_from_mask(-1)\n",
      "engine.compute_features_and_depths()\n",
      "all_features = engine.features_and_depths_as_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Splitting the data from this one object into training and test data,\n",
      "based on wether or not the pixel is above a set line\n",
      "'''\n",
      "cutoff = 140# where the split is for the train/test data\n",
      "\n",
      "X = np.array(all_features['patch_features'])\n",
      "X = nan_to_value(X,2.0)\n",
      "Y_gt = np.array(all_features['depth_diffs'])\n",
      "\n",
      "training_data =  all_features['indices'].T[0] < cutoff\n",
      "X_training = X[training_data, :]\n",
      "Y_training = Y_gt[training_data]\n",
      "print X_training.shape\n",
      "print Y_training.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training and fitting the forest\n",
      "rf = RandomForestRegressor(n_estimators=20,n_jobs=3,random_state=1,max_depth=20)\n",
      "rf.fit(X_training, Y_training)\n",
      "Y_pred_rf = rf.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training and fitting knn classifier\n",
      "knn = neighbors.KNeighborsClassifier(1, weights='uniform')\n",
      "knn.fit(X_training, Y_training)\n",
      "Y_pred_knn = knn.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (15.0, 18.0)\n",
      "\n",
      "# reconstructing prediction image\n",
      "idxs = all_features['indices'].transpose()\n",
      "prediction_rf = disp.reconstruct_image(idxs, Y_pred_rf, (240, 320))\n",
      "prediction_knn = disp.reconstruct_image(idxs, Y_pred_knn, (240, 320))\n",
      "GT_image = disp.reconstruct_image(idxs, Y_gt, (240, 320))\n",
      "GT_image[cutoff, :] = 0\n",
      "\n",
      "out = disp.crop_concatenate((GT_image, prediction_knn, prediction_rf), 10)\n",
      "plt.imshow(out)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# doing the voxel predictions of this view...\n",
      "\n",
      "import voxel_data\n",
      "\n",
      "def predict_per_tree(random_forest, X):\n",
      "    return np.array([tree.predict(X) for tree in random_forest.estimators_])    \n",
      "\n",
      "all_trees = predict_per_tree(rf, X)\n",
      "\n",
      "frontrender = engine.frontrender#(modelname, view_idx)\n",
      "#frontrender = compute_data.load_frontrender(modelname, view_idx)\n",
      "depth_predictions = np.array([reconstruct_image(idxs, tree, (240, 320)) for tree in all_trees])\n",
      "back_predictions = depth_predictions + frontrender\n",
      "\n",
      "#vol = volume_convert(frontrender, depth_predictions, 304.6,start_depth=-1, end_depth=-1)\n",
      "V = voxel_data.scene_voxels(frontrender, back_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# showing a slice.\n",
      "# should really make basically all of this part of the voxel routine...\n",
      "plt.rcParams['figure.figsize'] = (16.0, 16.0)\n",
      "slice_idx = 120\n",
      "warped_shape = V.extract_warped_slice(slice_idx=slice_idx, maxdepth=4.2)[0:120, :]\n",
      "plt.subplot(1, 2, 1)\n",
      "im = engine.frontrender\n",
      "im[slice_idx, :] = 1\n",
      "plt.imshow(im)\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.imshow(warped_shape[:, 200:520])\n",
      "plt.ylim((0, warped_shape.shape[0]))\n",
      "plt.show()\n",
      "print V.vol.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "# getting individual tree predictions for each value...\n",
      "all_trees = predict_per_tree(clf, X)\n",
      "var = np.var(all_trees, axis=0)\n",
      "var_image = reconstruct_image(idxs, var, (240, 320))\n",
      "\n",
      "# aim is to get a variance image\n",
      "plt.imshow(var_image)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# trying to do as above but with the class...\n",
      "import voxel_data\n",
      "reload(voxel_data)\n",
      "\n",
      "frontrender = engine.frontrender#(modelname, view_idx)\n",
      "#frontrender = compute_data.load_frontrender(modelname, view_idx)\n",
      "depth_predictions = np.array([reconstruct_image(idxs, tree, (240, 320)) for tree in all_trees])\n",
      "back_predictions = depth_predictions + frontrender\n",
      "\n",
      "#vol = volume_convert(frontrender, depth_predictions, 304.6,start_depth=-1, end_depth=-1)\n",
      "V = voxel_data.scene_voxels(frontrender, back_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(voxel_data)\n",
      "warped_shape = V.extract_warped_slice(120, maxdepth=4.2)[0:120, :]\n",
      "plt.imshow(warped_shape)\n",
      "plt.ylim((0, warped_shape.shape[0]))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print all_images.shape\n",
      "print np.nanmax(all_images)\n",
      "print np.nanmin(all_images)\n",
      "\n",
      "slice_height = 120\n",
      "forest_slices = all_images[:, slice_height, :]\n",
      "output_image = np.zeros((100,320))\n",
      "\n",
      "# populate the output image with the depth predictions\n",
      "for eachslice in forest_slices:\n",
      "    for idx, prediction in enumerate(eachslice):\n",
      "        if ~np.isnan(prediction):\n",
      "            scaled_depth = int(prediction * 16)\n",
      "            output_image[0:scaled_depth, idx] += 1\n",
      "output_image /= forest_slices.shape[0]\n",
      "print thisslice.shape\n",
      "plt.imshow(output_image)\n",
      "plt.colorbar()\n",
      "plt.show()\n",
      "\n",
      "\n",
      "# need conversion factor to translate "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}