{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn import neighbors\n",
      "import cPickle as pickle\n",
      "import compute_data\n",
      "import voxel_data\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import paths\n",
      "\n",
      "models_list = paths.base_path + 'databaseFull/fields/models.txt'\n",
      "\n",
      "def nans(shape, dtype=float):\n",
      "    a = np.empty(shape, dtype)\n",
      "    a.fill(np.nan)\n",
      "    return a\n",
      "\n",
      "def nan_to_value(X, newval):\n",
      "\tX[np.isnan(X)] = newval\n",
      "\treturn X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading in the data and running the prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelname = '109d55a137c042f5760315ac3bf2c13e'\n",
      "view_idx = 12\n",
      "\n",
      "# loading the features to test on and the ground truth data\n",
      "engine = compute_data.depth_feature_engine(modelname, view_idx+1)\n",
      "engine.sample_from_mask(-1)\n",
      "engine.compute_features_and_depths()\n",
      "all_features = engine.features_and_depths_as_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array(all_features['patch_features'])\n",
      "X = nan_to_value(X, -10)\n",
      "Y_gt = np.array(all_features['depth_diffs'])\n",
      "Y_gt = nan_to_value(Y_gt, 0)\n",
      "cutoff = 110\n",
      "to_use =  all_features['indices'].T[0] < cutoff\n",
      "X_subset = X[to_use, :]\n",
      "X_subset += np.random.normal(0, 0.0001, X_subset.shape)\n",
      "Y_subset = Y_gt[to_use]\n",
      "print X_subset.shape\n",
      "print Y_subset.shape\n",
      "assert(Y_subset.shape[0] > 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf = RandomForestRegressor(n_estimators=20,n_jobs=3,random_state=1,max_depth=12)\n",
      "rf.fit(X_subset, Y_subset)\n",
      "Y_pred = rf.predict(X)\n",
      "# computing error\n",
      "#error = np.mean(np.abs(Y_pred - Y_gt))\n",
      "#print \"Error is \" + str(error)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (15.0, 18.0)\n",
      "\n",
      "def reconstruct_image(indices, values, shape):\n",
      "    '''\n",
      "    return image of size `shape` with `values` in the positions indicated by `indices`\n",
      "    '''\n",
      "    out = nans(shape)\n",
      "    out[indices[0], indices[1]] = values\n",
      "    return out\n",
      "\n",
      "def crop_concatenate(im1, im2, padding=0):\n",
      "    '''\n",
      "    puts im1 and im2 next to each other, and crops each of them for better display\n",
      "    '''\n",
      "    mask = ~np.isnan(im1)\n",
      "    left = compute_data.findfirst(np.any(mask, axis=0)) - padding\n",
      "    right = mask.shape[1] - compute_data.findfirst(np.any(mask, axis=0)[::-1]) + padding\n",
      "    top = compute_data.findfirst(np.any(mask, axis=1)) - padding\n",
      "    bottom = mask.shape[0] - compute_data.findfirst(np.any(mask, axis=1)[::-1]) + padding\n",
      "    return np.concatenate((GT_image[top:bottom, left:right], output_prediction[top:bottom, left:right]), axis=1)\n",
      "\n",
      "# reconstructing prediction image\n",
      "idxs = all_features['indices'].transpose()\n",
      "output_prediction = reconstruct_image(idxs, Y_pred, (240, 320))\n",
      "GT_image = reconstruct_image(idxs, Y_gt, (240, 320))\n",
      "\n",
      "out = np.concatenate((GT_image[:, 50:250], output_prediction[:, 50:250]), axis=1)\n",
      "out[cutoff, :] = 0\n",
      "plt.imshow(out)\n",
      "#plt.imshow(crop_concatenate(GT_image, output_prediction, 10))\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (15.0, 18.0)\n",
      "# doing NN classification\n",
      "knn = neighbors.KNeighborsClassifier(1, weights='uniform')\n",
      "knn.fit(X_subset, Y_subset)\n",
      "Y_pred = knn.predict(X)\n",
      "\n",
      "output_prediction = reconstruct_image(idxs, Y_pred, (240, 320))\n",
      "GT_image = reconstruct_image(idxs, Y_gt, (240, 320))\n",
      "\n",
      "out = np.concatenate((GT_image[:, 50:250], output_prediction[:, 50:250]), axis=1)\n",
      "out[cutoff, :] = 0\n",
      "plt.imshow(out)\n",
      "plt.show()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loading in the training data from file to use\n",
      "import paths\n",
      "import scipy.io\n",
      "# doing NN classificatio\n",
      "train_data = scipy.io.loadmat(paths.combined_train_features_small)\n",
      "X_from_file = train_data['patch_features']\n",
      "#print np.nansum(X_from_file, axis=0)\n",
      "#plt.imshow(np.isnan(X_from_file[1000:1200, :]))\n",
      "Y_from_file = train_data['Y'].flatten()\n",
      "print X_from_file.shape\n",
      "print Y_from_file.shape\n",
      "#print X_from_file[1:100, :]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (15.0, 18.0)\n",
      "\n",
      "# load the model\n",
      "\n",
      "#\n",
      "  \n",
      "    # computing training data from other views of same object\n",
      "    features_per_view = 1000\n",
      "    all_patch_features = []\n",
      "    all_Y = []\n",
      "    for idx in range(42):\n",
      "        if idx == 12:\n",
      "            continue\n",
      "        engine = compute_data.depth_feature_engine(modelname, idx+1)\n",
      "        engine.sample_from_mask(features_per_view)\n",
      "        engine.compute_features_and_depths()\n",
      "        temp = engine.features_and_depths_as_dict()\n",
      "        all_Y.append(temp['depth_diffs'])\n",
      "        all_patch_features.append(temp['patch_features'])\n",
      "Y_from_other_views = np.array(all_Y).flatten()\n",
      "X_from_other_views = np.array(all_patch_features).reshape((41*features_per_view, -1))\n",
      "print Y_from_other_views.shape\n",
      "print X_from_other_views.shape\n",
      "#print np.sum(np.isnan(X_from_other_views), axis=0)\n",
      "X_from_other_views[np.isnan(X_from_other_views)] = -10\n",
      "\n",
      "knn = neighbors.KNeighborsClassifier(5, weights='uniform')\n",
      "knn.fit(X_from_other_views, Y_from_other_views)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X[X==0] = -20\n",
      "print X.shape\n",
      "Y_pred_knn = knn.predict(X)\n",
      "Y_pred_rf = rf.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
      "knn_im_pred = reconstruct_image(idxs, Y_pred_knn, (240, 320))\n",
      "rf_im_pred = reconstruct_image(idxs, Y_pred_rf, (240, 320))\n",
      "#output_prediction = reconstruct_image(idxs, Y_pred_knn, (240, 320))\n",
      "GT_image = reconstruct_image(idxs, Y_gt, (240, 320))\n",
      "\n",
      "#out = crop_concatenate((GT_image, rf_im_pred, knn_rf_pred), 15)\n",
      "out = np.concatenate((GT_image[:, 90:200], rf_im_pred[:, 90:200], knn_im_pred[:, 90:200]), axis=1)\n",
      "plt.imshow(out)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# want to show all the other views\n",
      "for idx in range(42):\n",
      "    engine = compute_data.depth_feature_engine(modelname, idx+1)\n",
      "    plt.subplot(6, 7, idx)\n",
      "    plt.imshow(engine.frontrender)\n",
      "#    plt.axes(False)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf = RandomForestRegressor(n_estimators=20,n_jobs=3,random_state=1,max_depth=12)\n",
      "rf.fit(X_from_other_views, Y_from_other_views)\n",
      "#Y_pred = rf.predict(X)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
      "plt.matshow(np.reshape(rf.feature_importances_, (15, 15)))\n",
      "plt.colorbar()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# doing the voxel predictions of this view...\n",
      "\n",
      "import voxel_data\n",
      "\n",
      "def predict_per_tree(random_forest, X):\n",
      "    return np.array([tree.predict(X) for tree in random_forest.estimators_])    \n",
      "\n",
      "all_trees = predict_per_tree(rf, X)\n",
      "\n",
      "frontrender = engine.frontrender#(modelname, view_idx)\n",
      "#frontrender = compute_data.load_frontrender(modelname, view_idx)\n",
      "depth_predictions = np.array([reconstruct_image(idxs, tree, (240, 320)) for tree in all_trees])\n",
      "back_predictions = depth_predictions + frontrender\n",
      "\n",
      "#vol = volume_convert(frontrender, depth_predictions, 304.6,start_depth=-1, end_depth=-1)\n",
      "V = voxel_data.scene_voxels(frontrender, back_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['figure.figsize'] = (16.0, 16.0)\n",
      "slice_idx = 120\n",
      "warped_shape = V.extract_warped_slice(slice_idx=slice_idx, maxdepth=4.2)[0:120, :]\n",
      "plt.subplot(1, 2, 1)\n",
      "im = engine.frontrender\n",
      "im[slice_idx, :] = 1\n",
      "plt.imshow(im)\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.imshow(warped_shape[:, 200:520])\n",
      "plt.ylim((0, warped_shape.shape[0]))\n",
      "plt.show()\n",
      "print V.vol.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "# getting individual tree predictions for each value...\n",
      "all_trees = predict_per_tree(clf, X)\n",
      "var = np.var(all_trees, axis=0)\n",
      "var_image = reconstruct_image(idxs, var, (240, 320))\n",
      "\n",
      "# aim is to get a variance image\n",
      "plt.imshow(var_image)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# trying to do as above but with the class...\n",
      "import voxel_data\n",
      "reload(voxel_data)\n",
      "\n",
      "frontrender = engine.frontrender#(modelname, view_idx)\n",
      "#frontrender = compute_data.load_frontrender(modelname, view_idx)\n",
      "depth_predictions = np.array([reconstruct_image(idxs, tree, (240, 320)) for tree in all_trees])\n",
      "back_predictions = depth_predictions + frontrender\n",
      "\n",
      "#vol = volume_convert(frontrender, depth_predictions, 304.6,start_depth=-1, end_depth=-1)\n",
      "V = voxel_data.scene_voxels(frontrender, back_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(voxel_data)\n",
      "warped_shape = V.extract_warped_slice(120, maxdepth=4.2)[0:120, :]\n",
      "plt.imshow(warped_shape)\n",
      "plt.ylim((0, warped_shape.shape[0]))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print all_images.shape\n",
      "print np.nanmax(all_images)\n",
      "print np.nanmin(all_images)\n",
      "\n",
      "slice_height = 120\n",
      "forest_slices = all_images[:, slice_height, :]\n",
      "output_image = np.zeros((100,320))\n",
      "\n",
      "# populate the output image with the depth predictions\n",
      "for eachslice in forest_slices:\n",
      "    for idx, prediction in enumerate(eachslice):\n",
      "        if ~np.isnan(prediction):\n",
      "            scaled_depth = int(prediction * 16)\n",
      "            output_image[0:scaled_depth, idx] += 1\n",
      "output_image /= forest_slices.shape[0]\n",
      "print thisslice.shape\n",
      "plt.imshow(output_image)\n",
      "plt.colorbar()\n",
      "plt.show()\n",
      "\n",
      "\n",
      "# need conversion factor to translate "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# showing forest importance\n",
      "plt.matshow(np.reshape(clf.feature_importances_, (15, 15)))\n",
      "#plt.show()\n",
      "plt.colorbar()\n",
      "\n",
      "print np.reshape(clf.feature_importances_, (15, 15))[7, 7]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    }
   ],
   "metadata": {}
  }
 ]
}